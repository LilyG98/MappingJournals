{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lily Grumbach\n",
    "    <br>M1 Humanités numériques - Université PSL</h4>\n",
    "<h1><center>Rendu TAIS-TAL </center></h1>\n",
    "<h2><center>Partie TAIS</center></h2>\n",
    "<h3><center>2/5 : Extraire des bases de données à ma disposition les coordonnées des lieux et créer un dictionnaire de désambiguisation de mes données</center></h3>\n",
    "\n",
    "<h3><u>PLAN:</u></h3>\n",
    "\n",
    "1) Harmonisation des données Géopolitiques pour le fond de carte de 1914\n",
    "<br/>\n",
    "    \n",
    "<h4> 2) Explorer les bases de données à ma disposition (IREL et GPH) et les préparer pour l'extraction des coordonnées géographiques </h4>\n",
    " \n",
    "3) Reconstituer les liens URL de la base de données IREL des Archives nationales d'Outre-mer.\n",
    "\n",
    "4) Reconstituer les coordonnées géographiques des GPH et de l'IREL\n",
    " \n",
    "5) Géoréférencer les données de mes revues\n",
    "<b>Stratégie en place :  </b>\n",
    "\n",
    "Nous avons 3 sources possibles de désambiguisation : \n",
    "* **Wikidata** indiqués par le medialab \n",
    "* l'**IREL**, la base de données géographique de l'inventaire en ligne des Archives nationales d'Outre Mer\n",
    "* **Geonames**, pour le meilleur et pour le pire.\n",
    "\n",
    "<h4>Objectifs de la partie : </h4>\n",
    "Faire une estimation de ce que je pourrai récupérer avec les données bases de données que j'ai et les préparer pour l'extraction de coordonnées géographiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module\n",
    "import desambiguisation\n",
    "\n",
    "##General : \n",
    "from desambiguisation import ListEntities2df\n",
    "##GPH\n",
    "from desambiguisation import MatchGPELOC_IREL,Extract_longlat_WikiData_ALL\n",
    "##IREL : \n",
    "from desambiguisation import nettoyage_df_IREL,urlencode,Extract_longlat_IREL,IREL_Nettoyage_AdminLieuDit,nettoyage_desambiguisation,EgaliserTaille_MatchNot_IREL\n",
    "\n",
    "#Généraux\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#Webscrapping\n",
    "from bs4 import BeautifulSoup\n",
    "import geocoder\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "#Wikidata \n",
    "import qwikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Les df de référence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AHMC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AHMC/AHMCGPE_ents.csv\n",
      "Output:liste des entités GPE_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AHMC/AHMCLOC_ents.csv\n",
      "Output:liste des entités LOC_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AHMC/AHMCORG_ents.csv\n",
      "Output:liste des entités ORG_ents \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##AHMC\n",
    "df_AHMC_annote = pd.read_csv('./df_annotes/dfAHMCannotations.csv')\n",
    "\n",
    "#Ne conserver qu'une partie du df\n",
    "df_AHMC_annote = df_AHMC_annote[[\"article_titre\",\"revue_annee\",\"GPE_ents\",\"LOC_ents\",\"ORG_ents\"]]\n",
    "\n",
    "#Extraire les entités GPE,LOC,ORG\n",
    "liste_GPEAHMC = ListEntities2df(df_AHMC_annote,\"AHMC\",\"GPE_ents\")\n",
    "liste_LOCAHMC = ListEntities2df(df_AHMC_annote,\"AHMC\",\"LOC_ents\")\n",
    "liste_ORGAHMC = ListEntities2df(df_AHMC_annote,\"AHMC\",\"ORG_ents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AMN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AMN/AMNGPE_ents.csv\n",
      "Output:liste des entités GPE_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AMN/AMNLOC_ents.csv\n",
      "Output:liste des entités LOC_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AMN/AMNORG_ents.csv\n",
      "Output:liste des entités ORG_ents \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AMN\n",
    "df_AMN_annote = pd.read_csv('./df_annotes/dfAMNannotations.csv')\n",
    "\n",
    "#Ne conserver qu'une partie du df\n",
    "df_AMN_annote = df_AMN_annote[[\"article_titre\",\"revue_annee\",\"GPE_ents\",\"LOC_ents\",\"ORG_ents\"]]\n",
    "\n",
    "#Extraire les entités GPE,LOC,ORG\n",
    "liste_GPEAMN = ListEntities2df(df_AMN_annote,\"AMN\",\"GPE_ents\")\n",
    "liste_LOCAMN = ListEntities2df(df_AMN_annote,\"AMN\",\"LOC_ents\")\n",
    "liste_ORGAMN = ListEntities2df(df_AMN_annote,\"AMN\",\"ORG_ents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Désambiguisation de la liste des GPE et LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lieux à annoter :  260\n"
     ]
    }
   ],
   "source": [
    "list_GPELOC = liste_GPEAMN+liste_LOCAMN+liste_LOCAHMC+liste_GPEAHMC\n",
    "print(\"Nombre de lieux à annoter : \",len(list_GPELOC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire et liste des Faux positifs relevés dans la liste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionnaire pour la désambiguisation :\n",
    "Dico_desambiguisation = {\"Guinée Française\":[\"Guinée française\"],\n",
    "                         \"Côte d'Ivoire\":[\"côte d'Ivoire\"],\n",
    "                         \"Pak-Hoi\":[\"Pak-Hoï\",\"Pakhoï\"],\n",
    "                         \"Chengdu\":['Tchen-Tou','Tchentou'],\n",
    "                         \"Yunnan\":['Yun-Nam','Yun-Nan','Yunnam'],\n",
    "                         \"Hanoi\":[\"Hanoï\"],\n",
    "                         \"Laokay\":[\"Lao-kay\"],\n",
    "                         \"Côte d'Ivoire\":[\"Côte d\\'Ivoire\",\"côte d'Ivoire\"]\n",
    "                        }\n",
    "Liste_FP = [\"Annamite\",\"Annamites\",\"île\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annamite\n",
      "Annamites\n",
      "île\n"
     ]
    }
   ],
   "source": [
    "#désambiguiser :\n",
    "for i in range(len(list_GPELOC)):\n",
    "    for (key,val) in Dico_desambiguisation.items():\n",
    "            for name in val:\n",
    "                if list_GPELOC[i]==name :\n",
    "                    list_GPELOC[i]=key\n",
    "\n",
    "#retirer lesfaux positifs :\n",
    "for FP in Liste_FP:\n",
    "    print(FP)\n",
    "    list_GPELOC.remove(FP)\n",
    "# list_GPELOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avant dédoublonnage :  257\n",
      "après dédoublonnage :  225\n"
     ]
    }
   ],
   "source": [
    "#Retirer les doublons de la liste :\n",
    "print(\"avant dédoublonnage : \",len(list_GPELOC))\n",
    "list_GPELOC = list(dict.fromkeys(list_GPELOC))\n",
    "print(\"après dédoublonnage : \",len(list_GPELOC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mise en df pour exploitation plus tard\n",
    "df_GPELOC = pd.DataFrame({\"NAME\":list_GPELOC})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taille finale des entités à annoter : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algérie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allemagne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angleterre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Annam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>lac Tchad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>île de Saint-Barthélémy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>île de Saint-Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>île de la Réunion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>îles Saint-Pierre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        NAME\n",
       "0                     Acores\n",
       "1                    Algérie\n",
       "2                  Allemagne\n",
       "3                 Angleterre\n",
       "4                      Annam\n",
       "..                       ...\n",
       "220               lac Tchad.\n",
       "221  île de Saint-Barthélémy\n",
       "222      île de Saint-Martin\n",
       "223        île de la Réunion\n",
       "224        îles Saint-Pierre\n",
       "\n",
       "[225 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GPELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportation pour exploitation future : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GPELOC.to_csv(\"./output/2-Exploration_GPH-IREL/GPELOC_à_annoter.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explorer les possibilités entre GPH, IREL et GPELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Importation et première exploration des BDD\n",
    "NB : je n'applique cela qu'aux BDD GPH et IREL car Geonames est beaucoup trop volumineux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. GPH \n",
    "Import de la base de données du medialab contenant les liens wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import du df GPH entities avec lien wikidata\n",
    "df_wikiData = pd.read_csv(\"./GeoPolHist-202103/medialab-GeoPolHist-fb19b66/data/GeoPolHist_entities.csv\")\n",
    "df_wikiData=df_wikiData.rename(columns={\"GPH_name\":\"NAME\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des données de 1914 nettoyées et enrichies manuellement pour correspondre au fond de carte de QGIS. On merge ce df avec celui contenant les liens wikidata :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer le df de référence (jusqu'à 1914)\n",
    "df_MANUEL = pd.read_csv(\"./output_finaux/df_1914manuelCarto.csv\")\n",
    "\n",
    "#Merge avec les données complétées manuellement \n",
    "df_WikiQGIS=pd.merge(df_wikiData,df_MANUEL,how=\"right\",on=\"GPH_code\")\n",
    "\n",
    "#Export : \n",
    "df_WikiQGIS.to_csv(\"./output/2-Exploration_GPH-IREL/WikiQGIS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1.2. IREL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyer la base de donnée IREL (cf module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return: df_IREL nettoyé\n"
     ]
    }
   ],
   "source": [
    "dico_IREL ={}\n",
    "n=0\n",
    "\n",
    "with open('./IREL/liste_lieux_IREL.js','r') as f:\n",
    "    lignes = f.readlines()\n",
    "    \n",
    "    for l in lignes:\n",
    "        l=l.split(\"\\n\")\n",
    "        dico_IREL[n]=l\n",
    "        n+=1\n",
    "\n",
    "df_IREL = nettoyage_df_IREL(dico_IREL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Merge df_IREL et df_WikiData pour avoir les lieux présents dans les deux bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renommer les colonnes pour pouvoir merge :\n",
    "df_IREL=df_IREL.rename(columns={\"Lieu-dit\":\"NAME\"})\n",
    "df_wikiData=df_wikiData.rename(columns={\"GPH_name\":\"NAME\"})\n",
    "\n",
    "df_WikiIREL = pd.merge(df_wikiData,df_IREL,how=\"inner\",on=\"NAME\")\n",
    "\n",
    "#ATTENTION : je drop les duplicatas sur les GPH_code pour avoir une idée plus géographique qu'historique:\n",
    "df_WikiIREL[\"GPH_code\"]=df_WikiIREL[\"GPH_code\"].drop_duplicates(keep=\"first\")\n",
    "\n",
    "#Ici onsouhaite avoirleurnombredans l'absolu,regardless of the GPH Status\n",
    "df_WikiIREL=df_WikiIREL.loc[df_WikiIREL[\"GPH_code\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4.  Explorations de nos df :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> visualisation du nombre d'entité par df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_IREL</th>\n",
       "      <th>df_wikiData</th>\n",
       "      <th>df_WikiQGIS</th>\n",
       "      <th>df_WikiIREL</th>\n",
       "      <th>df_GPELOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nombre d'entités</th>\n",
       "      <td>14571</td>\n",
       "      <td>1228</td>\n",
       "      <td>203</td>\n",
       "      <td>87</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  df_IREL  df_wikiData  df_WikiQGIS  df_WikiIREL  df_GPELOC\n",
       "Nombre d'entités    14571         1228          203           87        225"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparaison_DF = pd.DataFrame({\"df_IREL\":len(df_IREL),\"df_wikiData\":len(df_wikiData),\"df_WikiQGIS\":len(df_WikiQGIS),\"df_WikiIREL\":len(df_WikiIREL),\"df_GPELOC\":len(df_GPELOC)},index=[\"Nombre d'entités\"])\n",
    "df_comparaison_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoir une idée du nombre d'entités que je peux **à priori** (pour le meilleur comme pour le pire) trouver dans les deux bases de données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GPELOC=df_GPELOC.rename(columns={\"entités à annoter\":\"NAME\"})\n",
    "\n",
    "#Nombre d'entités de GPELOC trouvable dans GPH: \n",
    "GPELOC_GPH =pd.merge(df_wikiData,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "#Nombre d'entités de GPELOC trouvable dans IREL: \n",
    "GPELOC_IREL =pd.merge(df_IREL,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "#Nombre d'entités de GPELOC dans IREL *et* das GPH : \n",
    "GPELOC_IRELGPH =pd.merge(df_WikiIREL,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "#Nombre d'entités de GPELOC dans GPH en 1914 :\n",
    "GPELOC_GPH1914 =pd.merge(df_WikiQGIS,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "df_comparaison_GPELOC = pd.DataFrame({\"avec GPH\":len(GPELOC_GPH),\"avec IREL\":len(GPELOC_IREL),\"IRELxGPH\":len(GPELOC_IRELGPH),\"GPH en1914\":len(GPELOC_GPH1914)},index=[\"Nombre d'entités\"])\n",
    "df_comparaison_GPELOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_ent_trouvables = GPELOC_GPH['NAME'].tolist()+GPELOC_IREL['NAME'].tolist()\n",
    "len(liste_ent_trouvables)\n",
    "# GPELOC_IREL['NAME'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A l'issue de cette première étude, on en conclut la stratégie d'action suivante:**\n",
    "\n",
    "   1) Trouver les `23 GPELOC` de la base de données `GPH` => Les retirer de la liste de recherche des GPELOC\n",
    "\n",
    "   2) Dans `IREL`, chercher les 103-11=`92 noms` de lieux restant \n",
    "\n",
    "   3) Chercher les 225-126 = `99` entités restantes avec `Geonames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportation du df_IREL pour exploitation dans le prochain notebook : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_IREL.to_csv(\"./output/2-Exploration_GPH-IREL/IREL_nettoye.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
