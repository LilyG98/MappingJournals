{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Lily Grumbach\n",
    "    <br>M1 Humanités numériques - Université PSL</h4>\n",
    "<h1><center>Rendu TAIS-TAL </center></h1>\n",
    "<h2><center>Partie TAIS</center></h2>\n",
    "<h3><center>2/3 : Extraire des bases de données à ma disposition les coordonnées des lieux et créer un dictionnaire de désambiguisation de mes données</center></h3>\n",
    "\n",
    "<b><u>PLAN:</u></b>\n",
    "1) Harmonisation des données Géopolitiques pour le fond de carte de 1914\n",
    "<br>\n",
    "    \n",
    "<h4>2) Reconstruire et adapter la base de l'IREL aux données à disposition</h4>\n",
    "<br/>\n",
    "    \n",
    "3) Géoréférencer les données de mes revues\n",
    "\n",
    "<b>Stratégie en place :  </b>\n",
    "\n",
    "Nous avons 3 sources possibles de désambiguisation : \n",
    "* **Wikidata** indiqués par le medialab \n",
    "* l'**IREL**, la base de données géographique de l'inventaire en ligne des Archives nationales d'Outre Mer\n",
    "* **Geonames**, pour le meilleur et pour le pire.\n",
    "\n",
    "<h3>Objectifs de la partie : </h3>\n",
    "1) A court terme : récupérer les coordonnées géographiques des lieux mentionnés dans notre revue\n",
    "\n",
    "\n",
    "2) A long terme : avoir à disposition une base de données géographique historique exploitable pour des projets futurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module\n",
    "import desambiguisation\n",
    "##General : \n",
    "from desambiguisation import ListEntities2df\n",
    "##GPH\n",
    "from desambiguisation import MatchGPELOC_IREL,Extract_longlat_WikiData\n",
    "\n",
    "##IREL : \n",
    "from desambiguisation import nettoyage_df_IREL,urlencode,Extract_longlat_IREL,IREL_Nettoyage_AdminLieuDit\n",
    "\n",
    "#Généraux\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#Webscrapping\n",
    "from bs4 import BeautifulSoup\n",
    "import geocoder\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "#Wikidata \n",
    "import qwikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Les df de référence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AHMC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AHMC/AHMCGPE_ents.csv\n",
      "Output:liste des entités GPE_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AHMC/AHMCLOC_ents.csv\n",
      "Output:liste des entités LOC_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AHMC/AHMCORG_ents.csv\n",
      "Output:liste des entités ORG_ents \n",
      "\n"
     ]
    }
   ],
   "source": [
    "##AHMC\n",
    "df_AHMC_annote = pd.read_csv('./df_annotes/dfAHMCannotations.csv')\n",
    "\n",
    "#Ne conserver qu'une partie du df\n",
    "df_AHMC_annote = df_AHMC_annote[[\"article_titre\",\"revue_annee\",\"GPE_ents\",\"LOC_ents\",\"ORG_ents\"]]\n",
    "\n",
    "#Extraire les entités GPE,LOC,ORG\n",
    "liste_GPEAHMC = ListEntities2df(df_AHMC_annote,\"AHMC\",\"GPE_ents\")\n",
    "liste_LOCAHMC = ListEntities2df(df_AHMC_annote,\"AHMC\",\"LOC_ents\")\n",
    "liste_ORGAHMC = ListEntities2df(df_AHMC_annote,\"AHMC\",\"ORG_ents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AMN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AMN/AMNGPE_ents.csv\n",
      "Output:liste des entités GPE_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AMN/AMNLOC_ents.csv\n",
      "Output:liste des entités LOC_ents \n",
      "\n",
      "fichier créé dans ./desambiguisation/Revue_ParEntityLabel/AMN/AMNORG_ents.csv\n",
      "Output:liste des entités ORG_ents \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#AMN\n",
    "df_AMN_annote = pd.read_csv('./df_annotes/dfAMNannotations.csv')\n",
    "\n",
    "#Ne conserver qu'une partie du df\n",
    "df_AMN_annote = df_AMN_annote[[\"article_titre\",\"revue_annee\",\"GPE_ents\",\"LOC_ents\",\"ORG_ents\"]]\n",
    "\n",
    "#Extraire les entités GPE,LOC,ORG\n",
    "liste_GPEAMN = ListEntities2df(df_AMN_annote,\"AMN\",\"GPE_ents\")\n",
    "liste_LOCAMN = ListEntities2df(df_AMN_annote,\"AMN\",\"LOC_ents\")\n",
    "liste_ORGAMN = ListEntities2df(df_AMN_annote,\"AMN\",\"ORG_ents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Désambiguisation de la liste des GPE et LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lieux à annoter :  260\n"
     ]
    }
   ],
   "source": [
    "list_GPELOC = liste_GPEAMN+liste_LOCAMN+liste_LOCAHMC+liste_GPEAHMC\n",
    "print(\"Nombre de lieux à annoter : \",len(list_GPELOC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire et liste des Faux positifs relevés dans la liste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionnaire pour la désambiguisation :\n",
    "Dico_desambiguisation = {\"Guinée Française\":[\"Guinée française\"],\n",
    "                         \"Côte d'Ivoire\":[\"côte d'Ivoire\"],\n",
    "                         \"Pak-Hoi\":[\"Pak-Hoï\",\"Pakhoï\"],\n",
    "                         \"Chengdu\":['Tchen-Tou','Tchentou'],\n",
    "                         \"Yunnan\":['Yun-Nam','Yun-Nan','Yunnam'],\n",
    "                         \"Hanoi\":[\"Hanoï\"],\n",
    "                         \"Laokay\":[\"Lao-kay\"],\n",
    "                         \"Côte d'Ivoire\":[\"Côte d\\'Ivoire\",\"côte d'Ivoire\"]\n",
    "                        }\n",
    "Liste_FP = [\"Annamite\",\"Annamites\",\"île\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annamite\n",
      "Annamites\n",
      "île\n"
     ]
    }
   ],
   "source": [
    "#désambiguiser :\n",
    "for i in range(len(list_GPELOC)):\n",
    "    for (key,val) in Dico_desambiguisation.items():\n",
    "            for name in val:\n",
    "                if list_GPELOC[i]==name :\n",
    "                    list_GPELOC[i]=key\n",
    "\n",
    "#retirer lesfaux positifs :\n",
    "for FP in Liste_FP:\n",
    "    print(FP)\n",
    "    list_GPELOC.remove(FP)\n",
    "# list_GPELOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avant dédoublonnage :  257\n",
      "après dédoublonnage :  225\n"
     ]
    }
   ],
   "source": [
    "#Retirer les doublons de la liste :\n",
    "print(\"avant dédoublonnage : \",len(list_GPELOC))\n",
    "list_GPELOC = list(dict.fromkeys(list_GPELOC))\n",
    "print(\"après dédoublonnage : \",len(list_GPELOC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mise en df pour exploitation plus tard\n",
    "df_GPELOC = pd.DataFrame({\"entités à annoter\":list_GPELOC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entités à annoter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algérie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allemagne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angleterre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Annam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>lac Tchad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>île de Saint-Barthélémy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>île de Saint-Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>île de la Réunion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>îles Saint-Pierre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           entités à annoter\n",
       "0                     Acores\n",
       "1                    Algérie\n",
       "2                  Allemagne\n",
       "3                 Angleterre\n",
       "4                      Annam\n",
       "..                       ...\n",
       "220               lac Tchad.\n",
       "221  île de Saint-Barthélémy\n",
       "222      île de Saint-Martin\n",
       "223        île de la Réunion\n",
       "224        îles Saint-Pierre\n",
       "\n",
       "[225 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GPELOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reconstituer les bases les coordonnées des BDD à ma disposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Importation et première exploration des BDD\n",
    "NB : je n'applique cela qu'aux BDD GPH et IREL car Geonames est beaucoup trop volumineux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. GPH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPH_code</th>\n",
       "      <th>NAME</th>\n",
       "      <th>continent</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>wikidata_alt1</th>\n",
       "      <th>wikidata_alt2</th>\n",
       "      <th>wikidata_alt3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>America</td>\n",
       "      <td>http://www.wikidata.org/entity/Q30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>America</td>\n",
       "      <td>http://www.wikidata.org/entity/Q797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>America</td>\n",
       "      <td>http://www.wikidata.org/entity/Q782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>America</td>\n",
       "      <td>http://www.wikidata.org/entity/Q11703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>America</td>\n",
       "      <td>http://www.wikidata.org/entity/Q1183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>9994</td>\n",
       "      <td>Ross Dependency</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>http://www.wikidata.org/entity/Q203073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>9998</td>\n",
       "      <td>Concessions in China</td>\n",
       "      <td>World</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1376651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>9999</td>\n",
       "      <td>Inter-Allied Commission of Control</td>\n",
       "      <td>World</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1665892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>0</td>\n",
       "      <td>League of Nations</td>\n",
       "      <td>World</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q38130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1</td>\n",
       "      <td>United Nations</td>\n",
       "      <td>World</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1228 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GPH_code                                NAME continent  \\\n",
       "0            2            United States of America   America   \n",
       "1            3                              Alaska   America   \n",
       "2            4                              Hawaii   America   \n",
       "3            5                      Virgin Islands   America   \n",
       "4            6                         Puerto Rico   America   \n",
       "...        ...                                 ...       ...   \n",
       "1223      9994                     Ross Dependency   Oceania   \n",
       "1224      9998                Concessions in China     World   \n",
       "1225      9999  Inter-Allied Commission of Control     World   \n",
       "1226         0                   League of Nations     World   \n",
       "1227         1                      United Nations     World   \n",
       "\n",
       "                                    wikidata wikidata_alt1 wikidata_alt2  \\\n",
       "0         http://www.wikidata.org/entity/Q30           NaN           NaN   \n",
       "1        http://www.wikidata.org/entity/Q797           NaN           NaN   \n",
       "2        http://www.wikidata.org/entity/Q782           NaN           NaN   \n",
       "3      http://www.wikidata.org/entity/Q11703           NaN           NaN   \n",
       "4       http://www.wikidata.org/entity/Q1183           NaN           NaN   \n",
       "...                                      ...           ...           ...   \n",
       "1223  http://www.wikidata.org/entity/Q203073           NaN           NaN   \n",
       "1224  https://www.wikidata.org/wiki/Q1376651           NaN           NaN   \n",
       "1225  https://www.wikidata.org/wiki/Q1665892           NaN           NaN   \n",
       "1226    https://www.wikidata.org/wiki/Q38130           NaN           NaN   \n",
       "1227     https://www.wikidata.org/wiki/Q1065           NaN           NaN   \n",
       "\n",
       "     wikidata_alt3 notes  \n",
       "0              NaN   NaN  \n",
       "1              NaN   NaN  \n",
       "2              NaN   NaN  \n",
       "3              NaN   NaN  \n",
       "4              NaN   NaN  \n",
       "...            ...   ...  \n",
       "1223           NaN   NaN  \n",
       "1224           NaN   NaN  \n",
       "1225           NaN   NaN  \n",
       "1226           NaN   NaN  \n",
       "1227           NaN   NaN  \n",
       "\n",
       "[1228 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import du df GPH entities avec lien wikidata\n",
    "with open (\"./GeoPolHist-202103/medialab-GeoPolHist-fb19b66/data/GeoPolHist_entities.csv\") as f :\n",
    "    df_wikiData = pd.read_csv(f)\n",
    "df_wikiData.rename(columns={\"GPH_name\":\"NAME\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ne conserver que les données qui nous intéressent, on le merge avec la base de données finale de la Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importer le df de référence (jusqu'à 1914)\n",
    "df_MANUEL = pd.read_csv(\"./output_finaux/df_1914manuelCarto.csv\")\n",
    "\n",
    "#Merge avec les données complétées manuellement \n",
    "df_WikiQGIS=pd.merge(df_wikiData,df_MANUEL,how=\"right\",on=\"GPH_code\")\n",
    "\n",
    "#Export : \n",
    "df_WikiQGIS.to_csv(\"./WikiQGIS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1.2. IREL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyer la base de donnée IREL (cf module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return: df_IREL nettoyé\n"
     ]
    }
   ],
   "source": [
    "dico_IREL ={}\n",
    "n=0\n",
    "\n",
    "with open('./IREL/liste_lieux_IREL.js','r') as f:\n",
    "    lignes = f.readlines()\n",
    "    \n",
    "    for l in lignes:\n",
    "        l=l.split(\"\\n\")\n",
    "        dico_IREL[n]=l\n",
    "        n+=1\n",
    "\n",
    "df_IREL = nettoyage_df_IREL(dico_IREL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Merge df_IREL et df_WikiData pour avoir les lieux présents dans les deux bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IREL=df_IREL.rename(columns={\"Lieu-dit\":\"NAME\"})\n",
    "df_wikiData=df_wikiData.rename(columns={\"GPH_name\":\"NAME\"})\n",
    "\n",
    "df_WikiIREL = pd.merge(df_wikiData,df_IREL,how=\"inner\",on=\"NAME\")\n",
    "\n",
    "#Attention : je drop les duplicatas sur les GPH_code pour avoir une idée plus géographique qu'historique:\n",
    "df_WikiIREL[\"GPH_code\"]=df_WikiIREL[\"GPH_code\"].drop_duplicates(keep=\"first\")\n",
    "\n",
    "#Ici onsouhaite avoirleurnombredans l'absolu,regardless of the GPH Status\n",
    "df_WikiIREL=df_WikiIREL.loc[df_WikiIREL[\"GPH_code\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4.  Explorations de nos df :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> visualisation du nombre d'entité par df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_IREL</th>\n",
       "      <th>df_wikiData</th>\n",
       "      <th>df_WikiQGIS</th>\n",
       "      <th>df_WikiIREL</th>\n",
       "      <th>df_GPELOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nombre d'entités</th>\n",
       "      <td>14571</td>\n",
       "      <td>1228</td>\n",
       "      <td>203</td>\n",
       "      <td>87</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  df_IREL  df_wikiData  df_WikiQGIS  df_WikiIREL  df_GPELOC\n",
       "Nombre d'entités    14571         1228          203           87        225"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comparaison_DF = pd.DataFrame({\"df_IREL\":len(df_IREL),\"df_wikiData\":len(df_wikiData),\"df_WikiQGIS\":len(df_WikiQGIS),\"df_WikiIREL\":len(df_WikiIREL),\"df_GPELOC\":len(df_GPELOC)},index=[\"Nombre d'entités\"])\n",
    "df_comparaison_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoir une idée du nombre d'entités que je peux **à priori** (pour le meilleur comme pour le pire) trouver dans les deux bases de données : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avec GPH</th>\n",
       "      <th>avec IREL</th>\n",
       "      <th>IRELxGPH</th>\n",
       "      <th>GPH en1914</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nombre d'entités</th>\n",
       "      <td>23</td>\n",
       "      <td>103</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  avec GPH  avec IREL  IRELxGPH  GPH en1914\n",
       "Nombre d'entités        23        103        11          11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wikiData=df_wikiData.rename(columns={\"GPH_name\":\"NAME\"})\n",
    "df_GPELOC=df_GPELOC.rename(columns={\"entités à annoter\":\"NAME\"})\n",
    "\n",
    "#Nombre d'entités de GPELOC trouvable dans GPH: \n",
    "GPELOC_GPH =pd.merge(df_wikiData,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "#Nombre d'entités de GPELOC trouvable dans IREL: \n",
    "GPELOC_IREL =pd.merge(df_IREL,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "#Nombre d'entités de GPELOC dans IREL *et* das GPH : \n",
    "GPELOC_IRELGPH =pd.merge(df_WikiIREL,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "#Nombre d'entités de GPELOC dans GPH en 1914 :\n",
    "GPELOC_GPH1914 =pd.merge(df_WikiQGIS,df_GPELOC,how=\"inner\",on=\"NAME\")[[\"NAME\"]]\n",
    "\n",
    "df_comparaison_GPELOC = pd.DataFrame({\"avec GPH\":len(GPELOC_GPH),\"avec IREL\":len(GPELOC_IREL),\"IRELxGPH\":len(GPELOC_IRELGPH),\"GPH en1914\":len(GPELOC_GPH1914)},index=[\"Nombre d'entités\"])\n",
    "df_comparaison_GPELOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abyssinie',\n",
       " 'Afrique',\n",
       " 'Afrique',\n",
       " 'Afrique',\n",
       " 'Afrique',\n",
       " 'Afrique',\n",
       " 'Afrique',\n",
       " 'Afrique',\n",
       " 'Amérique',\n",
       " 'Amérique',\n",
       " 'Amérique',\n",
       " 'Amérique',\n",
       " 'Amérique',\n",
       " 'Amérique',\n",
       " 'Antilles',\n",
       " 'Baoulé',\n",
       " 'Baoulé',\n",
       " 'Baoulé',\n",
       " 'Barbade',\n",
       " 'Battambang',\n",
       " 'Bengale',\n",
       " 'Bokoro',\n",
       " 'Bretagne',\n",
       " 'Bretagne',\n",
       " 'Cayenne',\n",
       " 'Cayenne',\n",
       " 'Chine',\n",
       " 'Congo',\n",
       " 'Constantine',\n",
       " 'Constantine',\n",
       " 'Constantine',\n",
       " 'Constantine',\n",
       " 'Constantine',\n",
       " 'Constantine',\n",
       " 'Constantine',\n",
       " 'Corse',\n",
       " 'Corse',\n",
       " 'Crète',\n",
       " 'Cuba',\n",
       " 'Dori',\n",
       " 'Extrême-Orient',\n",
       " 'France',\n",
       " 'Gabon',\n",
       " 'Gabon',\n",
       " 'Gibraltar',\n",
       " 'Gibraltar',\n",
       " 'Grand-Bassam',\n",
       " 'Guadeloupe',\n",
       " 'Guadeloupe',\n",
       " 'Guadeloupe',\n",
       " 'Guinée',\n",
       " 'Guyane',\n",
       " 'Guyane',\n",
       " 'Hanoi',\n",
       " 'Inde',\n",
       " 'Inde',\n",
       " 'Kampot',\n",
       " 'Kayes',\n",
       " 'Labé',\n",
       " 'Liptako',\n",
       " 'Martinique',\n",
       " 'Martinique',\n",
       " 'Méditerranée',\n",
       " 'Méditerranée',\n",
       " 'Mexique',\n",
       " 'Miquelon',\n",
       " 'Niger',\n",
       " 'Nioro',\n",
       " 'Nord',\n",
       " 'Ogooué',\n",
       " 'Ogooué',\n",
       " 'Oubangui',\n",
       " 'Oubangui',\n",
       " 'Philippines',\n",
       " 'Réunion',\n",
       " 'Réunion',\n",
       " 'Saigon',\n",
       " 'Saigon',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Louis',\n",
       " 'Saint-Philippe',\n",
       " 'Saint-Philippe',\n",
       " 'Sénégal',\n",
       " 'Sumatra',\n",
       " 'Tagant',\n",
       " 'Tagant',\n",
       " 'Tchad',\n",
       " 'Tombouctou',\n",
       " 'Tonkin',\n",
       " 'Tonkin',\n",
       " 'Tonkin',\n",
       " 'Tonkin',\n",
       " 'Tonkin',\n",
       " 'Wallis',\n",
       " 'Yunnan']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_ent_trouvables = GPELOC_GPH['NAME'].tolist()+GPELOC_IREL['NAME'].tolist()\n",
    "len(liste_ent_trouvables)\n",
    "GPELOC_IREL['NAME'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A l'issue de cette première étude, on en conclut la stratégie d'action suivante:**\n",
    "\n",
    "   1) Trouver les `23 GPELOC` de la base de données `GPH` => Les retirer de la liste de recherche des GPELOC\n",
    "\n",
    "   2) Dans `IREL`, chercher les 103-11=`92 noms` de lieux restant \n",
    "\n",
    "   3) Chercher les 225-126 = `99` entités restantes avec `Geonames`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Retrouver les coordonnées géographiques de chaque base de donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. GPH : retrouver par WikiData les coordonnées de tous les lieux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(Q\\d+)\"\n",
    "df_wikiData[\"Q_code\"] = df_wikiData[\"wikidata\"].str.extract(pattern)\n",
    "List_Q_code =df_wikiData[\"Q_code\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wikidata redirect detected.  Input entity id=Q16972714. Returned entity id=Q13108101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant correction. \n",
      "liste latitude :  1227 \n",
      "liste longitude :  1227 \n",
      "List_Q_code :  1228\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'L_NotMatch' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8a4e2f0e7888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Tâche EXTREMEMENT longue.A n'executer qu'une fois :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_longlatGPH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtract_longlat_WikiData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList_Q_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_longlatGPH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./GPH_coordonnees.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/Rendu_TAIS-TAL/TAIS/data/desambiguisation.py\u001b[0m in \u001b[0;36mExtract_longlat_WikiData\u001b[0;34m(List_Q_code)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_long\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList_Q_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mL_NotMatch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlengthDiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'L_NotMatch' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#Tâche EXTREMEMENT longue.A n'executer qu'une fois : \n",
    "df_longlatGPH = Extract_longlat_WikiData(List_Q_code)\n",
    "df_longlatGPH.to_csv(\"./GPH_coordonnees.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. GPH x IREL : avoir une idée de ce que l'on pouvait trouver dans les deux \n",
    "#### (et qu'il faut donc extraire de la liste de recherche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un plot pour avoir une idée des entités par continent que l'on trouve dans les deux \n",
    "\n",
    "df_WikiIREL[\"continent\"].value_counts().plot.bar(title='Proportion des lieux par continent présents sur IREL ET dans la bdd GPHE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(Q\\d+)\"\n",
    "df_WikiIREL[\"Q_code\"] = df_WikiIREL[\"wikidata\"].str.extract(pattern)\n",
    "List_Q_code =df_WikiIREL[\"Q_code\"].tolist()\n",
    "\n",
    "df_WikiIREL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_longlatGPH = Extract_longlat_WikiData(List_Q_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_longlatGPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WikiIREL_coord = pd.merge(df_longlatGPH,df_WikiIREL[['GPH_code', 'NAME', 'titre', 'Q_code']],how=\"left\",on=\"Q_code\")\n",
    "\n",
    "df_WikiIREL_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_WikiIREL_coord[\"NAME\"].sample(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract_longlat_WikiData(List_Qcode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORGANISATION IREL : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_IREL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reconstituer les URL de IREL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#encoder les titres\n",
    "list_titre_encoded =[]\n",
    "for titre in df_IREL[\"titre\"]:\n",
    "    titre_encoded=urlencode(titre)\n",
    "    list_titre_encoded.append(titre_encoded)\n",
    "\n",
    "df_IREL[\"titre_encoded\"] = list_titre_encoded\n",
    "\n",
    "#reconstituer l'URL\n",
    "list_url=[]\n",
    "for encoded in df_IREL[\"titre_encoded\"]:\n",
    "    IREL_url= \"http://anom.archivesnationales.culture.gouv.fr/geo.php?ir=&lieu=\"+encoded\n",
    "    list_url.append(IREL_url)\n",
    "    \n",
    "df_IREL[\"IREL_url\"] = list_url\n",
    "\n",
    "#Chercher les coordonnées de chaque entrée:\n",
    "#Beautiful Soup\n",
    "pattern_coord_lat = r\"\\\"value\\\"\\:\\{\\\"latitude\\\"\\:(-?[\\d]{1,2}\\.[\\d]*)\\,\"\n",
    "pattern_coord_long = r\"longitude\\\"\\:(-?[\\d]{1,3}\\.[\\d]*)\\,\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Par économie de mémoire et de temps, à l'issue de la récupération des URL nous les avons exporté dans un csv trouvable ici : \"./output_finaux/ListeCoordonnees.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### LISTE des coordonnées récupérée et exportée dans \"./output_finaux/ListeCoordonnees.csv\"\n",
    "\n",
    "# liste_coords=[]\n",
    "# for url in df_IREL[\"IREL_url\"]: \n",
    "#     coords = desambiguisation.Extract_longlat_IREL(url)\n",
    "#     liste_coords.append(coords)\n",
    "# df_IREL[\"Coordonnees\"]=liste_coords\n",
    "# df_IREL[\"Coordonnees\"].to_csv(\"./output_finaux/ListeCoordonnees.csv\",sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IREL[\"Coordonnees\"]=pd.read_csv(\"./output_finaux/ListeCoordonnees.csv\",sep='\\t')\n",
    "df_IREL[\"Coordonnees\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nombre de coordonnées manquantes : \",df_IREL[\"Coordonnees\"].isna().sum())\n",
    "\n",
    "df_IREL.loc[df_IREL[\"Coordonnees\"].isna()][\"titre\"].sample(n=30)\n",
    "\n",
    "#5805 noms de lieux sans coordonnées géographiques. \n",
    "#Il faudrait pour cela revoir les url constitués pour voir s'ils fonctionnent bien\n",
    "##Le problème tient notamment à des problèmes de ponctuation, d'espace et d'appostrophe\n",
    "##Question à régler plus tard pour avoir à l'avenir une bdd pertinente et réutilisable par toutes et tous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IREL[\"Coordonnees\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des colonnes Aministration et Lieu-dit du df IREL \n",
    "\n",
    "Les deux colonnes en questions nous permettront de déterminer si oui ou non le lieu est géolocalisé dans la base de donnée IREL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_IREL=IREL_Nettoyage_AdminLieuDit(df_IREL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IREL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#On récupère tous les noms de lieu: \n",
    "liste_colnames= ['Administration', 'NAME','Administration_bis',\n",
    "       'Lieu-dit_bis']\n",
    "\n",
    "liste_entites_clean=[]\n",
    "for colname in liste_colnames:\n",
    "    liste_entites_clean+=df_IREL[colname].to_list()\n",
    "    \n",
    "while None in liste_entites_clean:\n",
    "        liste_entites_clean.remove(None)\n",
    "\n",
    "liste_entites_clean\n",
    "\n",
    "#Avoir une liste avec 1seule occurence de nom de lieu :\n",
    "IREL_listeclean = pd.DataFrame(liste_entites_clean).rename(columns={0:\"entites\"})\n",
    "IREL_listeclean = IREL_listeclean.groupby(by=\"entites\").sum().index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IREL_listeclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IREL_listeclean2=[]\n",
    "for placeName in IREL_listeclean:\n",
    "    \n",
    "    if re.search(r\" $\",placeName):\n",
    "        placeName=placeName.replace(re.search(r\" $\",placeName).group(0),\"\")    \n",
    "\n",
    "    if re.search(r\"^ \",placeName):\n",
    "        placeName=placeName.replace(re.search(r\"^ \",placeName).group(0),\"\")\n",
    "    \n",
    "    IREL_listeclean2.append(placeName)\n",
    "# IREL_listeclean2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chercher quels noms de lieux de la liste de mon df se trouve dans celle des IREL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_MatchDF_IREL, L_NotMatchDF_IREL =MatchGPELOC_IREL(list_GPELOC,IREL_listeclean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPLORATION DES DEUX LISTES POUR COMPRENDRE CE QUI N'EST PAS PASSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from desambiguisation import EgaliserTaille_MatchNot_IREL,nettoyage_desambiguisation,MatchGPELOC_IREL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pour que les deux listes aient la même longueur:\n",
    "# lengthDiff=len(L_NotMatchDF_IREL)-len(L_MatchDF_IREL)\n",
    "# L_MatchDF_IREL += list(np.empty(shape = (lengthDiff)))\n",
    "\n",
    "L_MatchDF_IREL,L_NotMatchDF_IREL=EgaliserTaille_MatchNot_IREL(L_MatchDF_IREL,L_NotMatchDF_IREL)\n",
    "\n",
    "comparaison_matchIREL = pd.DataFrame({'L_MatchDF_IREL' : L_MatchDF_IREL,\n",
    "                                'L_NotMatchDF_IREL' : L_NotMatchDF_IREL},\n",
    "                                columns=['L_MatchDF_IREL','L_NotMatchDF_IREL'])\n",
    "#Pour exploration manuelle\n",
    "comparaison_matchIREL.to_csv(\"./check_comparaisonMatchIREL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionnaire pour la désambiguisation :\n",
    "Dico_desambiguisation = {\"Guinée Française\":[\"Guinée française\"],\n",
    "                         \"Côte d'Ivoire\":[\"côte d'Ivoire\"],\n",
    "                         \"Pak-Hoi\":[\"Pak-Hoï\",\"Pakhoï\"],\n",
    "                         \"Chengdu\":['Tchen-Tou','Tchentou'],\n",
    "                         \"Yunnan\":['Yun-Nam','Yun-Nan','Yunnam'],\n",
    "                         \"Hanoi\":[\"Hanoï\"],\n",
    "                         \"Laokay\":[\"Lao-kay\"],\n",
    "                         \"Côte d\\'Ivoire\":[\"Côte d'Ivoire\",\"côte d'Ivoire\"]\n",
    "                        }\n",
    "Liste_FP = [\"Annamite\",\"Annamites\",\"île\",\"Croyance\",\"Port\"]\n",
    "\n",
    "#Problemes:\n",
    "#Guinée trop flou pour être assigné à \"Guinée française\" car à la même époque existait\n",
    "# une Guinée allemande et une britannique..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nettoyage en fonction de la désambiguisation \n",
    "liste_GPELOC = nettoyage_desambiguisation(Dico_desambiguisation,list_GPELOC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_MatchDF_IREL2, L_NotMatchDF_IREL2 = MatchGPELOC_IREL(list_GPELOC,IREL_listeclean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour que les deux listes aient la même longueur:\n",
    "lengthDiff=abs(len(L_NotMatchDF_IREL2)-len(L_MatchDF_IREL2))\n",
    "\n",
    "if len(L_NotMatchDF_IREL2) > len(L_MatchDF_IREL2):\n",
    "    L_MatchDF_IREL2 += list(np.empty(shape = (lengthDiff)))\n",
    "    print(\"nouvelle taille L_Match_IREL2\",len(L_Match_IREL2))\n",
    "    \n",
    "elif len(L_NotMatchDF_IREL2) < len(L_MatchDF_IREL2):\n",
    "    L_NotMatchDF_IREL2 += list(np.empty(shape = (lengthDiff)))\n",
    "    print(\"nouvelle taille L_NotMatch_IREL2\",len(L_NotMatchDF_IREL2))\n",
    "\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Différence de taillent entre les deux listes : \",lengthDiff)\n",
    "print(\"taille de L_NotMatchDF_IREL2 : \",len(L_NotMatchDF_IREL2))\n",
    "print(\"taille de L_MatchDF_IREL2 : \",len(L_MatchDF_IREL2))\n",
    "\n",
    "comparaison_matchIREL = pd.DataFrame({'L_MatchDF_IREL' : L_MatchDF_IREL2,\n",
    "                                'L_NotMatchDF_IREL' : L_NotMatchDF_IREL2},\n",
    "                                columns=['L_MatchDF_IREL','L_NotMatchDF_IREL'])\n",
    "#Pour exploration manuelle\n",
    "comparaison_matchIREL.to_csv(\"./check_comparaisonMatchIREL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pour les entités trouvées : les associer aux df AHMC et AMN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_matchIREL.to_csv(\"./desambiguisation/comparaison_match_IREL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparaison_matchIREL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintenant on cherche à extraire de ` df_IREL ` les coordonnées des lieux qui ont matché "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble = pd.DataFrame()\n",
    "for placeName in L_MatchDF_IREL2:\n",
    "    df_placeName=df_IREL.loc[df_IREL[\"titre\"].str.contains(placeName)]\n",
    "    df_placeName[\"placeName\"]=placeName\n",
    "    df_ensemble=pd.concat([df_ensemble,df_placeName])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble[\"placeName\"]=df_ensemble[\"placeName\"].drop_duplicates(keep=\"first\")\n",
    "df_ensemble_byPlaceName = df_ensemble.groupby(by=\"placeName\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ensemble_byPlaceName=df_ensemble_byPlaceName.drop(columns=[\"titre_encoded\",\"Administration_bis\",\"Lieu-dit_bis\"])\n",
    "df_ensemble_byPlaceName.to_csv(\"./desambiguisation/IREL_parlieuxreconnus.csv\")\n",
    "\n",
    "#Nécessité de nettoyer IREL_url des localisations multiples. Nous n'en avons pas besoin car il nous suffit d'avoir un point en sont sein \n",
    "# df_ensemble_byPlaceName[\"IREL_url\"].str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_byPlaceName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_byPlaceName_freq = df_ensemble.groupby(by=\"placeName\").count().IREL_url\n",
    "df_byPlaceName_freq.sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_byPlaceName_freq.loc[df_byPlaceName_freq<3000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geonames \n",
    "source: https://www.geonames.org/export/web-services.html\n",
    "\n",
    "username= lgrumbach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "URL=\"Chine\"\n",
    "\n",
    "Geonames_url_base =\"http://api.geonames.org/postalCodeLookupJSON?placename=\"+URL+\"&username=lgrumbach\"\n",
    "Geonames_url_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = urlencode(\"Abala, Subdivision (République du Congo)\")\n",
    "url_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3 : trouver les coordonnées Wikidata GPH\n",
    "## LISTE DES PROPERTIES :  https://www.wikidata.org/wiki/Wikidata:Database_reports/List_of_properties/all \n",
    "\n",
    "## European Colonialism :https://www.wikidata.org/wiki/Wikidata:WikiProject_European_Colonialism\n",
    "\n",
    "## list of colonial empires:https://www.wikidata.org/wiki/Wikidata:WikiProject_European_Colonialism/list_of_colonial_empires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REssource pour seformer à SPARQL sur Wikidata : \n",
    "https://www.wikidata.org/wiki/Wikidata:SPARQL_tutorial#SPARQL_basics\n",
    "\n",
    "\n",
    "Ce dont j'ai besoin:\n",
    "SELCT ?coord\n",
    "WHERE\n",
    "{\n",
    "#?coord has coord QID\n",
    "    ?coord wd:QID\n",
    "}\n",
    "\n",
    "\n",
    "Items= wd: /// properties = wdt:.  \n",
    "=> wdt AVANT wd\n",
    "\n",
    "* \";\" = AND\n",
    "* \".\" = fin d'une requête\n",
    "* \",\" = pour ajouter un item aux mêmes propriétés\n",
    "* \"[]\" = Recherche relative.  Inside the brackets, you can specify predicate-object pairs, just like after a ;\n",
    "* \"p\" : points not to the object, but to a statement node.\n",
    "    *  This node then is the subject of other triples: \n",
    "        * ps: (for property statement) points to the statement object,\n",
    "        * pq: (property qualifier) to qualifiers, \n",
    "        * prov:wasDerivedFrom points to reference nodes (which we’ll ignore for now).\n",
    "\n",
    "\n",
    "AJouter : \n",
    "SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE]\". }\n",
    "=> Sert à afficher le label associé à l'entité recherchée\n",
    "\n",
    "**Instances and classes**\n",
    "\n",
    "\"has\" // \"is\" \n",
    "[objet particulier] IS [concept/subclass] \n",
    "=> différencier concept et subclass -> essayer de remplacer \"is\" par \"is a kind of\". SI ça marche, c'est une subclass. Sinon un concept. \n",
    "ex: Gone with the wind \"is a kind of\" film =>  marche pas => film est un concept\n",
    "\n",
    "\n",
    "**Property paths**\n",
    "\n",
    "\n",
    "wdt:P31/wdt:P279/wdt:P279 \n",
    "P31 = nature de l'el\n",
    "P279 =sous-classede [eltavant]\n",
    "\n",
    "wdt:\n",
    "* **P31** = nature del'élt\n",
    "* **P625** = coordonnées géo\n",
    "* **P17**\t= country\n",
    "* **P530**\tdiplomatic relation\n",
    "* rdfs:label \"Mary Wollstonecraft\"@en;\n",
    "* **P945** =\tallegiance\tcountry (or other power) that the person or organization serves\n",
    "* **P1376**\tcapital of\tcountry, state, department, canton or other administrative division of which the municipality is the governmental seat\n",
    "* **P8119**\tHASC\tcodes to represent country subdivisions\n",
    "* **Q133156** colony \n",
    "* **Q161243** dependent territory\n",
    "\n",
    "=> pour éviter de listertoutes lessubclass, on peut écrire \"*\" ou \"+\" comme enregex\n",
    "\n",
    "**Qualifiers**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Globe oordinates**\n",
    "\n",
    "Coordinate text values have value type globecoordinate and property type globe-coordinate.\n",
    "\n",
    "The simple value of the coordinate is the WKT string with the coordinates, with type geo:wktLiteral, e.g.: \"Point(35.3 12.93)\"^^geo:wktLiteral. The order of the coordinates in WKT is longitude, latitude (since format version 0.0.2).\n",
    "\n",
    "The full value has latitude, longitude and precision as double, and the globe as IRI.\n",
    "\n",
    "\n",
    "**Wikibase Entity Id** \n",
    "\n",
    "Wikibase Entity Id values have value type wikibase-entityid and property type wikibase-item.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Faire lien avec les données wikidata de GPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraire les entity ID de chaque lien wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikidata_extractID(df,ncol):\n",
    "\n",
    "    ListEntityID = []\n",
    "    for i in range (len(df)):\n",
    "        wikiurl = df.iloc[i,ncol]\n",
    "    #     print(type(wikiurl))\n",
    "        if type(wikiurl) is float:\n",
    "            ListEntityID.append(wikiurl)\n",
    "        else:\n",
    "            entityID = re.search(r'[A-Z][0-9]+$',wikiurl).group(0)\n",
    "            ListEntityID.append(entityID)\n",
    "    return ListEntityID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wikidata\n",
    "wikiURL1 = wikidata_extractID(df_WikiQGIS,3)\n",
    "df_WikiQGIS[\"entityID_1\"]=wikiURL1\n",
    "\n",
    "#wikidata_alt1\n",
    "wikiURLalt1 = wikidata_extractID(df_WikiQGIS,4)\n",
    "df_WikiQGIS[\"entityID_alt1\"]=wikiURLalt1\n",
    "\n",
    "#wikidata_alt2\n",
    "wikiURLalt2 = wikidata_extractID(df_WikiQGIS,5)\n",
    "df_WikiQGIS[\"entityID_alt2\"]=wikiURLalt2\n",
    "\n",
    "#NB: il n'y a pas de wikidata_alt3 pour la période concernée\n",
    "df_WikiQGIS.iloc[2,14]\n",
    "df_WikiQGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_WikiQGIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des coordonnées via l'API wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essai Beautiful Soup\n",
    "pattern_coord_lat = r\"\\\"value\\\"\\:\\{\\\"latitude\\\"\\:(-?[\\d]{1,2}\\.[\\d]*)\\,\"\n",
    "pattern_coord_long = r\"longitude\\\"\\:(-?[\\d]{1,3}\\.[\\d]*)\\,\"\n",
    "\n",
    "def Extract_longlat (url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, features=\"lxml\")\n",
    "    div_ens_tag = soup.find_all(\"div\", {\"class\":\"tableau1\"})\n",
    "    \n",
    "    lattitude = re.search(pattern_coord_lat,r.text).group(1)\n",
    "    longitude = re.search(pattern_coord_long,r.text).group(1)\n",
    "    return (lattitude,longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_long=[]\n",
    "list_lat=[]\n",
    "list_nan = []\n",
    "for i in range (len(df_WikiQGIS)):\n",
    "    url = df_WikiQGIS.iloc[i,3]\n",
    "    if type(url) is float:\n",
    "            list_nan.append(url)\n",
    "    else:\n",
    "        Extract_longlat(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY iD\n",
    "\n",
    "Properties used: \n",
    "instance of (P31)  \n",
    "View with Reasonator View with SQID, subclass of (P279)  \n",
    "View with Reasonator View with SQID, coordinate location (P625)  \n",
    "View with Reasonator View with SQID, area (P2046)  \n",
    "View with Reasonator View with SQID\n",
    "\n",
    "Countries : \n",
    "\n",
    "?country wdt:P31 wd:Q3624078 . # sovereign state\n",
    "    ?article schema:about ?country ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESSAI 1 : qwikidata\n",
    "# pip install qwikidata\n",
    "from qwikidata.entity import WikidataItem\n",
    "from qwikidata.linked_data_interface import get_entity_dict_from_api\n",
    "from qwikidata.sparql import (get_subclasses_of_item,\n",
    "                              return_sparql_query_results)\n",
    "\n",
    "Q_ID = \"Q889\"\n",
    "subclasses_of_entity = get_subclasses_of_item(Q_ID)\n",
    "subclasses_of_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pywikibot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pip install \"mwparserfromhell>=0.5.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Essai 2 : pywikibot \n",
    "# pip install \"mwparserfromhell>=0.5.0\"\n",
    "import pywikibot\n",
    "import mwparserfromhell\n",
    "import pwb\n",
    "# pywikibot.login()\n",
    "\n",
    "usernames['wikidata']['en'] = 'LilyGENC'\n",
    "\n",
    "site = pywikibot.Site(\"en\",\"wikidata\")\n",
    "repo = site.data_repository()\n",
    "item = pywikibot.ItemPage(repo, \"Q889\")\n",
    "item_dict = item.get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IREL \n",
    "\n",
    "http://anom.archivesnationales.culture.gouv.fr/geo.php?ir="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_IREL.to_csv(\"./IREL/irel_essai.csv\")\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstitution des URL IREL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTF8 encode => URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urlIREL=\"http://anom.archivesnationales.culture.gouv.fr/geo.php?ir=&lieu=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Aboisso+Como%C3%A9+%28C%C3%B4te+d%27Ivoire%29\"\n",
    "df_IREL.iloc[4,5].strip(r\"\\\"\\'\\''\\,\\;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IREL[\"Localité\"][df_IREL[\"Localité\"]==\"Zuytpeene\"].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexes(dfObj, value):\n",
    "      \n",
    "    # Empty list\n",
    "    listOfPos = []\n",
    "      \n",
    "    # isin() method will return a dataframe with \n",
    "    # boolean values, True at the positions    \n",
    "    # where element exists\n",
    "    result = dfObj.isin([value])\n",
    "      \n",
    "    # any() method will return \n",
    "    # a boolean series\n",
    "    seriesObj = result.any()\n",
    "  \n",
    "    # Get list of column names where \n",
    "    # element exists\n",
    "    columnNames = list(seriesObj[seriesObj == True].index)\n",
    "     \n",
    "    # Iterate over the list of columns and\n",
    "    # extract the row index where element exists\n",
    "    for col in columnNames:\n",
    "        rows = list(result[col][result[col] == True].index)\n",
    "  \n",
    "        for row in rows:\n",
    "            listOfPos.append((row, col))\n",
    "              \n",
    "    # This list contains a list tuples with \n",
    "    # the index of element in the dataframe\n",
    "    return listOfPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling getIndexes() function to get \n",
    "# the index positions of all occurrences\n",
    "# of 22 in the dataframe\n",
    "listOfPositions = getIndexes(df_IREL, \"Zuytpeene\")\n",
    "  \n",
    "print('Index positions of 22 in Dataframe : ')\n",
    "  \n",
    "# Printing the position\n",
    "for i in range(len(listOfPositions)):\n",
    "    print(listOfPositions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
